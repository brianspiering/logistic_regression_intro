{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "690d943b",
   "metadata": {},
   "source": [
    "<center><h2>Introduction to Logistic Regression</h2></center>\n",
    "<center><h2>By Brian Spiering</h2></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a1e66e",
   "metadata": {},
   "source": [
    "<center><h2>Motivating Story</h2></center>\n",
    "<br>\n",
    "<br>\n",
    "<center>Are these malignant or benign cells?</center>\n",
    "<center><img src=\"images/This-is-a-magnified-image-of-a-malignant-breast-FNA-The-visible-cell-nuclei-have-been.png\" width=\"75%\"/></center>\n",
    "\n",
    "<center><a href=\"https://www.researchgate.net/figure/This-is-a-magnified-image-of-a-malignant-breast-FNA-The-visible-cell-nuclei-have-been_fig1_2302195\">Image source</a></center>\n",
    "<br>\n",
    "<br>\n",
    "Imagine you are working as a Data Scientist at a medical research company. You are helping medical professionals decided if tissue biopsy  images contain cells that are malignant or benign. This task is directly related to a cancer diagnosis. \n",
    "\n",
    "You do not have enough labeled data for deep learning. You have collaborated with domain experts to extract information about cell nucleus properties.\n",
    "\n",
    "Ten real-valued features are computed for each cell nucleus:\n",
    "\n",
    "a) radius (mean of distances from center to points on the perimeter) <br>\n",
    "b) texture (standard deviation of gray-scale values) <br>\n",
    "c) perimeter <br>\n",
    "d) area <br>\n",
    "e) smoothness (local variation in radius lengths) <br>\n",
    "f) compactness (perimeter^2 / area - 1.0) <br>\n",
    "g) concavity (severity of concave portions of the contour) <br>\n",
    "h) concave points (number of concave portions of the contour) <br>\n",
    "i) symmetry <br>\n",
    "j) fractal dimension (\"coastline approximation\" - 1) <br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb0b39a",
   "metadata": {},
   "source": [
    "<center><h2>Learning Outcomes</h2></center>\n",
    "\n",
    "__By the end of this session, you should be able to__:\n",
    "\n",
    "- Describe logistic regression in your own words.\n",
    "- Write and explain the formula for logistic regression.\n",
    "- Make a prediction with a trained logistic regression model.\n",
    "- Draw the decision boundary for logistic regression.\n",
    "- List when and when not to use logistic regression.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f678fb9",
   "metadata": {},
   "source": [
    "<center><h2>Linear Regression Review</h2></center>\n",
    "\n",
    "Let's do a quick review of linear regression.\n",
    "\n",
    "Let's predict the target as the symmetry of the cell nucleus (continuous valued). \n",
    "\n",
    "Features will be properties of the cell nucleus: radius, texture, smoothness ‚Ä¶.\n",
    "<br>\n",
    "<br>\n",
    "<center>Data: A single feature predicts a target</center>\n",
    "<center><img src=\"images/15642961290066_logr_gen_1.png\" width=\"75%\"/></center>\n",
    "\n",
    "Supervised learning algorithm because each data point has a label / target value.\n",
    "\n",
    "<center>Best fit line</center>\n",
    "<br>\n",
    "<center><img src=\"images/15642962536507_logr_gen_2.png\" width=\"75%\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59050497",
   "metadata": {},
   "source": [
    "<center><h2>Linear regression: Mathematical formalism</h2></center>\n",
    "\n",
    "Model it as a linear combination of one or more features:\n",
    "\n",
    "$$ yÃÇ = Œ≤_0 + Œ≤_1x_1 + ‚Ä¶ + Œ≤_px_p = Œ≤_0 + \\sum_{i=1}^{p} Œ≤_ix_i = Œ≤_0 + \\vec{x^T} \\vec{Œ≤}$$\n",
    "\n",
    "The $Œ≤_0$ term is non elegant (aka, kinda awkward).  \n",
    "Let's clean it up with \"add vector of 1s\" technique.\n",
    "\n",
    "$$\\vec{x} = [1, x_1, x_2, ‚Ä¶, x_p]$$\n",
    "\n",
    "$$\\vec{Œ≤} = [Œ≤_0, Œ≤_1, Œ≤_2, ‚Ä¶, Œ≤_p]$$\n",
    "\n",
    "$$ yÃÇ = \\vec{x^T} \\vec{Œ≤}$$\n",
    "\n",
    "or commonly notated as\n",
    "\n",
    "$$ yÃÇ = xŒ≤$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882e952f",
   "metadata": {},
   "source": [
    "<center><h2>Linear regression: Loss function</h2></center>\n",
    "\n",
    "$$ MSE(Œ≤) = \\frac{1}{n}\\sum_{i=1}^{n} (y_i - yÃÇ_i)^2 $$\n",
    "\n",
    "<center>Best fit line</center>\n",
    "<center><img src=\"images/15642962536507_logr_gen_2.png\" width=\"75%\"/></center>\n",
    "\n",
    "<center>Make prediction</center>\n",
    "<center><img src=\"images/15643029750927_logr_gen_3.png\" width=\"75%\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a6e012",
   "metadata": {},
   "source": [
    "<center><h2>Any questions about linear regression?</h2></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3eb4297",
   "metadata": {},
   "source": [
    "<center><h2>Logistic Regression: Different kind of target</h2></center>\n",
    "\n",
    "For binary classification, target variable (y) can take one of two discrete outcomes (classes):\n",
    "\n",
    "- Yes / No\n",
    "- Present / Absent\n",
    "- Pass / Fail\n",
    "- Win / Loss\n",
    "- Go / No go\n",
    "- Malignant / Benign\n",
    "\n",
    "We have to encode it as indicator variable: 0 or 1.\n",
    "\n",
    "The goal is train a binary classifier to be make decision about the class of a new observation.\n",
    "\n",
    "Also, a supervised learning algorithm because each data point has a label / target value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805b50f6",
   "metadata": {},
   "source": [
    "<center><h2>Comparing Linear Regression to Logistic Regression</h2></center>\n",
    "\n",
    "<br>\n",
    "<center><img src=\"images/1_Ubge8qVlc4Xk58H1oMp4Zw.jpeg\" width=\"75%\"/></center>\n",
    "\n",
    "\n",
    "\n",
    "Linear regression fits a line to the data.\n",
    "\n",
    "Logistic regression fits a logistic function / \"S\" shaped curve to the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3582d3",
   "metadata": {},
   "source": [
    "<center><h2>Logistic Function</h2></center>\n",
    "\n",
    "<br>\n",
    "<center><img src=\"images/logistic_function_graph.png\" width=\"75%\"/></center>\n",
    "\n",
    "Also called sigmoid function.\n",
    "\n",
    "The sigmoid functions takes continuous input values and output values 0 to 1.\n",
    "\n",
    "I like calling it the squashing function - It squashes the values to bound them 0 and 1.\n",
    "\n",
    "Sigmoid generates a smooth transition from class 0 to class 1 by giving probability of class 1:\n",
    "\n",
    "$$ P(y=1 | x)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ee47b7",
   "metadata": {},
   "source": [
    "<center><h2>Logistic Function: Mathematical formalism</h2></center>\n",
    "\n",
    "\n",
    "Sigmoid function:  \n",
    "\n",
    "$$ œÉ (z) = \\frac{1}{1+‚ÑØ^{-z}} = \\frac{‚ÑØ^z}{1+‚ÑØ^z}$$\n",
    "\n",
    "e is a mathematical constant whic is ~2.718.\n",
    "\n",
    "Substituting the vectorized linear equations into sigmoid function:\n",
    "\n",
    "$$ œÉ(xŒ≤) = \\frac{1}{1+‚ÑØ^{-xŒ≤}} = \\frac{‚ÑØ^{xŒ≤}}{1+‚ÑØ^{xŒ≤}}$$\n",
    "\n",
    "The result is probability of class 1 for given instance:\n",
    "\n",
    "$$œÉ(x_iŒ≤) = P(y=1 | x_i)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4d1d1c",
   "metadata": {},
   "source": [
    "<center><h2>Logistic Function: Loss function</h2></center>\n",
    "\n",
    "The goal of the loss is to find the parameters $Œ≤$ that maximize the probability of the true y labels {0, 1} in the training data given the observations $x$. \n",
    "\n",
    "Let's define the loss function and then solve for Œ≤ that gives minimum loss value.\n",
    "\n",
    "$$   Likelihood(Œ≤) = \\prod\\limits_{i=1}^n\n",
    "\\begin{cases}\n",
    "P(x_i;Œ≤)  \\text{    if $y_i$ = 1 }\\\\\n",
    "1- P(x_i;Œ≤) \\text{ if $y_i$ = 0 }\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Products are computational complex and sometimes result in numerical underflow errors.\n",
    "\n",
    "So let's convert product to summation by taking the log:\n",
    "\n",
    "$$   Likelihood(Œ≤) = \\sum_{i=1}^n\n",
    "\\begin{cases}\n",
    "log(P(x_i;Œ≤))  \\text{    if $y_i$ = 1 }\\\\\n",
    "log(1- P(x_i;Œ≤)) \\text{ if $y_i$ = 0 }\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "We can either maximize the log of likelihood function or minimize the negative of log likelihood.\n",
    "\n",
    "Typically it is optimized through gradient descent (I'm going to save gradient descent for another time) so we want to minimize the negative of log likelihood.\n",
    "\n",
    "Also called the cross-entropy loss."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b146df6",
   "metadata": {},
   "source": [
    "<center><h2>How do we make a decision? </h2></center>\n",
    "\n",
    "We need to make a decision about specific image. Given cell properties, do we predict malignant or benign?\n",
    "\n",
    "We have a trained model $P(y=1|x)$.\n",
    "\n",
    "Given a specific example (an instance with certain feature values), \n",
    "\n",
    "<br>\n",
    "<center><img src=\"images/prediction.png\" width=\"75%\"/></center>\n",
    "\n",
    "For a specific instance $x_i$, we say yes if the probability P(y = 1|x) is more than threshold and no otherwise. We call the threshold the decision boundary:\n",
    "\n",
    "$$   decision =\n",
    "\\begin{cases}\n",
    "1  & \\text{if P(y=1|x) > threshold} \\\\\n",
    "0 & \\text{otherwise}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Typically, the threshold is 0.5. But the threshold should be adjust for the business requirements.\n",
    "\n",
    "In other words, the logistic regression model itself simply models probability of output (target label) in terms of input (vectorized features). The logistic regression model does not perform statistical classification and is not a classifier.\n",
    "\n",
    "The logistic regression model can be used to make a classifier by adding a threshold or decision value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d8e3125",
   "metadata": {},
   "source": [
    "<center><h2>Decision Boundary</h2></center>\n",
    "\n",
    "<br>\n",
    "<center><img src=\"images/boundary.png\" width=\"75%\"/></center>\n",
    "\n",
    "In classification problems with two or more classes, a decision boundary is a hypersurface that separates the underlying vector space into sets, one for each class\n",
    "\n",
    "For logistic regression it will be hyperplane, aka straight line.\n",
    "\n",
    "<br>\n",
    "<center><img src=\"images/moons.png\" width=\"75%\"/></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "609e29e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAADPCAYAAAAeYh3LAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAA5LUlEQVR4nO2deXhU5dXAfycz2UhCWMIagoAgKK5oqWJdqrVVRKhLUVxwqVVp0aq0LsXa5dNPrdXqJ0irtFpcca0WsYoKYkUFBAVR2bewhck+CVlm5v3+mJkwmS0zyUxmyfk9zzwmd+5975mRvOeeXYwxKIqiKIovGYkWQFEURUk+VDkoiqIoAahyUBRFUQJQ5aAoiqIEoMpBURRFCUCVg6IoihKAKgclZRCRv4rIb9tx3WARsYuIJR5yJSsi8raIXJloOZTURLTOQYkHIrINuNYY816q3ltErgL+DhwAXMBWYKYxZkFHZVSUZEctB0UJzyfGmHygB/A48KKI9Ij1TbqaVaMkP6oclE5FRLJF5BER2e15PSIi2T7v3yYiezzvXSsiRkSGe957WkTu8fxcJCILRKRKRCpE5CMRyRCRZ4DBwL89rqTbRGSIZx2r59peIvKU5x6VIvKvtuQ2xriAZ4A8YITPZ/mziOwQkX0et1duFJ9ljogsFJE64PsiMlBEXhWR/SKyVURu8llrrIisFJEaz70e9hzPEZFnRaTc812sEJF+nveWiMi1np8zROQuEdkuImUiMk9ECj3veb+fKz2fxSYiM9v9P1lJC1Q5KJ3NTOBE4FjgGGAscBeAiJwN3Ar8ABgOnBZmnRlAKdAH6Af8BjDGmCuAHcB5xph8Y8yfglz7DNANGA30Bf7SltCeJ/urgWZgu+fwA8Bhns8yHCgG7o7is1wK3AsUAMuAfwNfetY5E7hZRH7kOfdR4FFjTHfgUOAlz/ErgUKgBOgN3IDbDebPVZ7X94FhQD4wy++c7wEjPfe+W0QOD/OVKGmOKgels7kM+KMxpswYsx/4A3CF573JwFPGmHXGmHrPe6FoBgYAhxhjmo0xH5kIAmgiMgA4B7jBGFPpufbDMJecKCJVQAPwZ+ByY0yZiAjwM+AWY0yFMaYW+F/gkig+yxvGmI89VslRQB9jzB+NMU3GmC3Akz7rNQPDRaTIGGM3xnzqc7w3MNwY4zTGfG6MqQlyr8uAh40xW4wxduBO4BKvNeXhD8aYA8aYL3ErqWPCfC9KmqPKQelsBnLwyRvPzwN93tvp857vz/48CGwC3hWRLSJyR4T3LwEqjDGVEZ7/qTGmB9ATeBM4xXO8D27r43OPO6cK+I/nOET2WXyPHQIM9K7lWe83uK0igJ/itlK+9biOJniOPwO8gzsWsltE/iQimUHuFex7t/qsD7DX5+d63NaF0kVR5aB0Nrtxb4ReBnuOAewBBvm8VxJqEWNMrTFmhjFmGHAecKuInOl9O8z9dwK9og0qe562fw5cISLHATbc7pvRxpgenlehJ3gd6WfxlXMnsNVnrR7GmAJjzHjP/TcaY6bgdoM9ALwiInkey+cPxpgjgHHABGBqkHsF+94dwL5ovgel66DKQYknmZ6AqfdlBV4A7hKRPiJShNtH/6zn/JeAq0XkcBHp5nkvKCIyQUSGe9w7NYDT8wL3hjcs2HXGmD3A28DjItJTRDJF5NRIPowxphyYC9ztcQU9CfxFRPp6ZCr2iRFE/Fk8LAdqROR2EckVEYuIHCki3/GsfbmI9PHct8pzjVNEvi8iR3liIjW43UzOIOu/ANwiIkNFJB+3C2y+McYRyWdXuh6qHJR4shD307X39XvgHmAlsAZYC6zyHMMY8zbwf8Bi3C6jTzzrNAZZewTwHmD3nPe4MWaJ5737cCugKhH5VZBrr8C9iX4LlAE3R/GZHgHGi8jRwO0eOT8VkRqPPCPb8VkwxjhxW0DH4q6nsOFWRIWeU84G1omIHXdw+hJjTAPQH3gFt2L4BviQg8rWl3/gdkEt9azfANwYxedWuhhaBKckLZ5sma+A7FR/wk2nz6J0DdRyUJIKETlfRLJEpCdu3/q/U3UzTafPonQ9VDkoycb1wH5gM27f+bTEitMh0umzKF0MdSspiqIoAajloCiKogSgykFRFEUJwNr2KbHnyaVb1JelKDHmw9m/4pmbTsdd+qEoETDuxpD/WNRyUJQ0oK6migHdXKoYlJihykFR0oDtaz7mtKMHJ1oMJY1Q5aAoacCuNf/ljGMOaftERYkQVQ6KkuI4HQ4KMprolpOVaFGUNCIhAelgCIbCTBc5FpLSb2qMocEJ1c0ZGJJPPqXrsnvbRk4Y0j3RYihpRtIoh8JMFz3ycnCJFZJQOWAMOcYBdQ1UNeu4XyV52Lrs39z6kyMSLYaSZiSNWynHQvIqBgARXGIlR/WCkmQ0lpdSmJ/b9omKEgVJoxxEJHkVgxeRpHR5KV2X8n27GdE3R/9dKjEnaZRDsrDyvx/w0/O+x9XjT2L+3McSLY6ihGX3hi/53qgBiRZDSUNUOfjgdDqZfe9vuOfx53jijQ9Z8va/2L55faLFUpSQ7P5iCWePHZFoMZQ0JGkC0tHwy6nnU11TE3C8sHt3Hp33ervXXb92NQMGD2FAiTtf/LRzJvHJ4nc45NCR7V5TUeKFw9FMT2ujupSUuJCSyqG6poYR180KOL7xiekdWre8bC99+he3/F7UbwDr16zu0JqKEi82r/2c8cf2T7QYSpoSM7eSZyD6ahFZEKs1O5tgsy30qUxJVsq++ojvjByUaDGUNCWWMYdf4h5wnrIU9RvA/r27Wn637dtDr779EiiRooSmybadQX17JloMJU2JiVtJRAYB5wL3ArfGYs1EMPLIY9m9fSt7S3fQu19/Pnz7DW5/4PFEiwXAfdOnYLfXBhzPzy/gzlkvJEAiJZHUVNgYUqS1DUr8iFXM4RHgNqAgRuslBIvVys9/87/MvGEKLqeTH55/CUOGJ0cw2m6vZdi1gam1W+bemABplETz7afv8POTD020GEoa02HlICITgDJjzOcicnqY864DrgO4fMY9nDpxSrvvWdi9e9Dgc2H3jveXGXvqmYw99cwOr6Mo8cSx51uOPe+7iRZDSWNiYTmcDEwUkfFADtBdRJ41xlzue5Ix5gngCej4JLiOpKsqSqrjdDgwdeWaLKHElQ4HpI0xdxpjBhljhgCXAB/4KwZFUWLH5lUfcu4JQxMthpLmaIW0oqQYe75ZwSmjNYVViS8xLYIzxiwBlsRyTcVNfn5B0OBzfn5K5wAoUeJyOpGavfTvfVSiRVHSnJSskO6KaLqqAlBbVcFRJfpAoMQfdSspSgqx4eN/86PjdFa0En9UOfjw8G9v4eLTjuT6809PtCiKEpSabV8x+pC+iRZD6QKocvDhrEmTuWfO84kWQ1GCUlNpo7i7YLXqOEIl/qS0cqiuLOfemy6npqoiJusddcJJFBRqrxolOdm9/gvGjdTBPkrnkNLK4YN/PYdr95e8//qziRZFUeLOluXv8eNxydHORUl/UlY5VFeWs3rRKzxywSBWL3olZtaDoiQrA/IMFkvK/skqKUbK/kv74F/Pcd5wGNEvl/OGo9aDktbs2rKekX2zEy2G0oVISeXgtRouPb4QgEuPL1TrQUlrtixbwI9P0lnRSueRksrBazX0zs8E3P+NhfVw323TuOXyCZRu28zlZ47hP69p5pKSHNSVbeeQ/r0SLYbShUjJCum1yz/ioz0NvLCmtNXxHvs/4vyrb2r3unf+aU5HRVOUmFNTYWNYb3Up+WOrsnP9/c/yxJ1X0LswL9HipB0pqRzunvNyokVQlE5j+4a1XHBccaLFSDrmvbWMyr07+eeCj7n1sh8mWpy0IyWVg6KkM/4jYesr9vJmjwL6FuayfM4vEihZ8mCrsrPgwxXMuaCIaQtWcOWEk9V6iDEpGXNQlHTGOxLW++o16kSOuv4v2GobEy1a0jDvrWVMGJ7ByL7ZTBiewT8XfBzxtbYqOxfe8VfKq+viKGHqkzTKwRgDpkMD4uKPMW45FaWTqN+zke79ShItRlLhtRqmjnFbClPH5LHgwxURb/a+7iglNEmjHBqckGEcyasgjCHDOGhwJloQpStRu2E5/UYel2gxkgqv1VCU7/aKF+VbI7YefN1R0SiUrkjSxByqmzOgroEcC0k5G9cYQ4PTI6eidALGGJqr9tCtZ+K6sCZjRtCSVRvYXdbI82vLWh0fuG9Dm4Hp1u6oBg1mhyFplINBqGq2QHOiJVGU5MDV3EBuQfBGkGOnzQ4agygqyI5p0DoZM4LefGh6u67zWg0vTXYPS5o6Jo/JL2kwOxRJoxwURXHjHQnbUFtJQZawbssngHvj92KrbWT0zx4KuHbdkzNiJke6ZQSFc0cli+JLJlQ5KEqS4R0Ju/jx23nqhpPIzspMiBzp5oLpiDuqK6LKQVGSkKbGBrpxIGGKIR1dMJG6o5IxzpIINLqqKEnIznUrOH10fAf7hMv370hGUKqjqa5u1HJQuhz+Fche8vMLWlw6iaZ03Wf8+oJD43qPcMHmRcu/4evN5Tz7ZQMZGQezB9PdBZNucZaOoMpB6XJ4K5D92TL3xgRIE8j//uIS9u/YwLL3W2cq+WYiFRVkBw0++watw9HWJnjW2MNprC5jwlknp7Uy8Cfd4iwdQZWDoiQZNVWVDD7lAg49eUKr477KoKPpquE2wa769JyOcZaOoDEHRUkymg/Y6XXIqLit31b7iWj7FqVLr6KuHGcJhloOStKSCrGBeOBsqqfHwKFxWz/cJjj13HFRPz0nY6Fce9BU19Z0WDmISAkwD+gPuIAnjDGPdnRdRUn22EA8qK0qx2rJQDIscbtHuE0QiKpQzNcFdd0by/lg1Qb+effVKemGaW/ldboSC8vBAcwwxqwSkQLgcxFZZIz5OgZrK0rM8VYge6navxcjGWRIBjOvmtDqvM62UHZtWU9OVlZc7xFuE5w4Y1ZUT8++LqjTiit5ee32lLcgFDcdVg7GmD3AHs/PtSLyDVAMqHJQkhL/DX/mVROSxkIpXf42JX17dCgTqSNE8/TsG8BtdrgYP9TJB5sMr7//WZcN4qYTMY05iMgQ4DjgsyDvXQdcB3D5jHs4deKUWN5a6QLs3bkFp9NJpa2s3U/4weIYlbYy9u7cQv+SYTGVtz3km1pW/i013Bu+sYu95TUM6WnhglGZfLSra6eApgsxUw4ikg+8CtxsjKnxf98Y8wTwBMCTS7ck6dAGJVlZN3cGjfZqxGLFGLA3OACw5HSDIEHrUASLY6yZNQ2nM/GDOnZv3cCo/vmJFiNivLGLZ7/cx/7KGvp0yyAjA/rkWVnwYddNAU0XYqIcRCQTt2J4zhjzWizWVBTf2ECDrYw+F/0eybAiGRnkFA0CYPfTN0NOaiXd1VZV8OKDv2bKbX8mv/Bgodu2le9xx7jEWy+R4nVBPfzcu7Drc249tbDlvYeXVqv1kOLEIltJgL8D3xhjHu64SIrixtdVNPOqCVisVrKLBnfKvffu3BLgvoLYBKlXvD0f6761LF/4ImdMmdZy3L5nMyMPOSPidZKlQZymgKYnsXjkOhm4AlgrIl94jv3GGLMwBmsrSsS0ty7CktONvS/eRWPRwYlrlbYycooGMeza1jMTIg1Sh5IlNyeH3lLD7POL+cWC1xk7/hLyC3vSUF/HgDwT1YafLPUFmgKansQiW+m/QPLN9VTSkgZbKcblavm9qbaCSvvBzbg9WUejr32ILXNv5N6nF7Qcc2cwBQ7TiZRQsmz4yxSuOrk7w/vmct6IuhbrYfMXH3PRdw+JeMNP9xYXyWIVdWVSy1mrxIVEViJHc2+LxUJTYyOZvYpbjmXkFjDwwt9gf+cvEd3Pv8bB93i8aa6rJt9Zw5QxJQBMGVPIpfPd1sP+rz9hwLmDI97wQ/VG6uimun77Ps7+5aO8+9jNjChpe3Z1LDdx37WSxSrqyqhyUBJaiRzpvfPzC7C/8xcqbWVk5vdqOZ6dX0j/kmFsifB+iWy7Ub16IZNGWemd5x7g0zsvk/NGwGdvvYDVXsa/l1ZE1BHUv77gewMa+PXi5Vw54eQOb6p3zH6FXtYD3PLwfLKzM9vc9GO5iXvXmv3yYpYs/zJtraJUQRvvKSnBnbNe4N6nF9CzqC9HT5/T8hrdAddPZ1O/dRUvr2vmlNmlLa/5axr46tP3OaR3TthmeL741heUV9sptDo4bWATj7+yuMXyCHVtONZv38fabzfz1I/z+HrjFnbtcFc7h2qs5+vaas/9Qq31wjvLOGeYhG38ly7N/pIZtRyUdhGpOyhVm+fFw/00+IoH2TL3Rmb4xDYAPnrxMaR2TcQ9jfzrC3rlZlBxwEWPTSu5+tjsds8iuGP2K1x6pJUj+1u5ZLSFlfucLPhwBXWNTUGtg1jOPvCu1bubhWzTyPhDDyrJYI3/1O0Uf1Q5KFSX29i1bWPQ46GI1B3UmS6rWG7oHVVckcpijMFp28qanaURp4MGqy/446JKXltXz9QxbpdbtLMIvFbD49fk43S4mHZCFt+fV8+5ox28+u4nzL+0tYsn2OyDC1+IvPGeb3zBGNOy1ryV1Vx2VCZWZwMOpyuokkz3YHyyoMqhC+N9qnc4myn790H3TEZWN4ovuw+XcYW5OjGE23STyRKJVJZ6ew3De2fyh5ujSwf135zF1cyZJc30yHV7itvqpuqP12rol59BU5OD4sIMLj0ykzfWV/ODQ60c2juz1XrB2n6fVtwUtvFeqIAzHOwEu2RTHbtrmnny8yawltI9LwdorSR1WlvnoMqhC+N9qrdu+hrJyGw5vm/+Xex++makE5RDtE/7yaQAYsHGT99l8jFtF/aNnTYbW21jy+8HaquZPKKB/eUOivL7sGJnA9+WOfj3Qwc3VIi8EG31+p0sb2pm7udVgEE8yekNDsM1x3XDVmVvZY34F765XIb9lbWM7JMVsnWGVyE8/spiFn92MOCclZOPrdK7Vg5k59A9Gwb2LQqoodBpbZ2HKocujm/PIl8sOd3Iz+kf9/un22YfLbYNK/nuGSe1fV5tI6N/dtC6WzPv97y+fR8vrauguMgAOXQvzAm6oUbCtjfuB+BHNz3KFxt2MKBXHjX1jUwe7kIEausbGNG7e4v14H8PXxdXsNYZvq6gi5//hAuP7Nby5E/x4RE/+YcbVKTWQ2xR5dDFcTbUM2Dqw4j14AyBZttOKhc+nHI9i1KNpsYG8qSRnOzMkOd4XTH+jQGPnvp7wD1XeuUzt8ZMph9993Caa8qYcNb3WLJqAx/ts/FRS68Dt5Xgb41E8jTv3dSH9crkzJJmcDaHPDcc2qqj89C/fqVdROoOSmTRWbKza+NXnDqqT9hzvK6YpvqO/6mGK1gbO202+6rqkdp9/N85Odz0wruYgn7069GH5XN+0aaM4Z7mfZVHebWda47L4sa36/j595xRP/lrq47OQ5VDktKZKaACGEdTy+/G5aDZXkF+0aEhr4lUhq7uNgpH6erF/PbSI0K+7+uK+dETu2iqryWrW/uVarj0T1ttIz1Hn8JZzo84/LCe/MRWySLLKdi+Xdbmum09zfsqj42VDYjAMf3gO4+V0qsgt9W54fCPu3gpKshuU4Ep0aPKIUnpjBTQ/PwCKm2bcdbsa3U8KzubnkV9dWOPEaFadDsqS8nJOjzkdb5ZOZNGWfjw83cpOeXCdsnQVvqn0+mk/tulXHRRdwAuOqaAF+e+xr7mHIZd3rrZsv9mHOpp3luoVn+gkf0VvsrDClg58tDo4iP+cRcvwabmKR1HlUMX5s5ZLzDzqgkUDxkR8F6k7SjCkaoFcLEmWIvusl3bGdWvGyLBe1b6+/EvPjKHN155hcp1H2GxWFrOCzU61N+F1Fb6Z1O9nclj8umV594SeuVZmXRYBq/IaYyeOLXV2pFuxl5LZcJZp2k8IAVR5ZAirJs7A2dDPc32ipiOyKzav5fVD0yhsHdRq+P+MYFoN/r7pk9h57bN9L/knlbHLRZLxE3y2ksyKaXaqgrWL309oEX3rnXLmTz6YANB/6KwH970CFOOOOjHHzeqHzedWg3Fx7QqBrv+/mcpr64LmTb6zwUfM/XccSEDxufc8TS22kbq7Hb++Ymdf36yFwARwRiDq9e37frcvpbKdW9EXhznJZgLaZethqonf8fJP/tDu2RSokOVQwqwbu4MDuwvpd/F92BcDixW9/+2aDfacK6qe/1aOkRzbajzM/N7BQznabTtiFje9tIel1wwhVJdbsO4HPTo0zqlNxols+Lt+Zw3goAW3XvWLeP08T9oOc+/KGy/rZwnl2czf11Tq/X8i8GCxRD8XUh1jU0hA8b7quqhoA+FP/k5+SWjWtbY+dQt7nN/+MuIPqc/vpbKacWVYYvjghHMheTaug/bgtj30tL24MFR5ZACOBvqQQSDgQwL3nEGTkdj2BYXSnh8FUKlrazFyrFYLPQvGcaubRspX/BwgKKJNO7jtRp+d7F7fKa3RfcJZ09mUOHBPz3fzfyn//oMS4bw3g2DmbagnpcfvBljTMDmFS6G4O9CmvfBKqziChowbqq3U2ypYffmjzmQc3B+dbO9EgCrJfpRLf5dY8cPdfLBJsPr73+WlMVqsezTlE6KRpVDkuKbAtpsrwBjyOw9yD1VSdwtEoyjKSlbXKQKvhbGmlnTWqycWFk3XqvBv0X3wqce5trje7Sc57uZ98m0cVQ/CyP79mqJDQABm1e4eQ7+LqQFm2p5+cEZAZuVrcrOCZf/nnvPHcKNb33O0DPOb8mGyihyB6YPH9z2TAd/fLOT9pbXMKSnhQtGZfLRro61urBahGZ7ZUDMI1TcJRJi3acpnRoCqnJIUvznJ1fsL0NEO6xD+2IKwWZCV9rK2LtzC/1LhsVFzo2rP2Z1WQPz15S2Ol7XtIQf3eB21/hu5ja7gwp7I+NPzMbhdDF1TB7nzvuEyho7r185gBvfdm9evo3qoHUMIZoK4nlvLWPSKAvDinKYNOIAi/yyoYoKsoMGn9vajL2prX9fuYtdtlpKeljJtgp98qwhW2tEwuGD++Iq6s6WZ2NX9BfLPk3p1hBQlUOK0VxeivGxFlwuJzOvmtDpwda9O7fgdDoDNlxfOSw53dj99M2trmu2V1AyJHT9RCS0J6bgdDrJzO/V6ro1s6YFVB7Hkuv/9GzQ44sf/jm9urd2ARXlW3l4STmTRmYypKcFW5Wd/r2703TAzoRDDb2zmlrNNgilALwb87wv9rKnoo4BvfKwWjJCVjX//rvuyviLjingjVeW0nT8D1ush/bWDnjTU4+74o+MLKpj/KhcfjfeHXwP1lojUcS6T1O6NQRU5ZAqGCd7/nkzTnsFFu8kNGPILOzPsGsfi8gP3p5qZe9TenW5jc/vv7jluKu5ieye/THGYG9w0GSvBGMoL9vDzyeMxdXcREZmFmJcrQK6+UWHxl2JBfuclbYycooGxfW+wfCvcdi/axujigtb3vctINtlqyUDFw990oDFUkf3PDv2uiamj82juraOS48t4tJXVpCdm99SN+BymZZspUH7NrRq571g0YdMOOt7QTco70bWJ99Kw/6ddAPO6d/AS3+9hdyCwlbWQSR+dP9z1m/fR0V5BbPH5/CLhXZe3bCHrEx3Cm4kBW/ttVrCyRTqO4hFn6Z0bAioyiEFcBerldH3vBns+9cD9L/sT4C7stm/gC0ckWzK/i4bb6B2gCdI6+Xz+y/m6OlzWDNrGgOveoQDZTvILCrBOJrIzMpm99M3c/T0ORFlQsWaYJ9z5lUTGBZmapyvldNsr6CxqG9LtlKwkaWR4l/jsOnTd/nVOLflZKuyk5lp5Z1Zvw66gZx/22yOsjYxrHc2e+1OaD7AhOEZrRrVHVQCJ4ecdzDhlGO58/HXWm2SB5USuP8lAeTyneGBhWmR+NH9z7lj9itceWwWE0blsny3i7WO/rz+p8gtkVhUPLcldyz7NHkVDcCFT+3kickDU74hoCqHFODOWS+4N+33/g/TUIvLRyH4FkTFAn+XjTdQ2xkpqJ2NJacbe1+8i8aivuRCS6PBjlg3vpaCMSagxsFZuYMjhrq7sIZtZ1FlZ+W6rWzPNSzcVIPLBfvra+nTszuDPJtXKB+3v3vj9lkvU122u9V9Iq1MjsSP7n/OuGMOaxkcBDBtbA6n/GMzG3eWMaIk+gB3e4hE7lj2afIqmlnLquhhbWppDZLKDQFVOaQI3s0qVEVzpCSqQKw9RXShzo8Vo699KMCy8d7XN44STk5/fC0FoFWNw2dvvUBBoztFtK3Na95by7joiEyuOe5gt9y5qxp4aSNY66XlHH8ft3/B27iSTO59dwNvXjOI3y6J3s0RiR/d/5xpD8zj0iOtDMh3P7gMyLdw6ZFWbnvs5aish47Q2f7/Nx+ajq3KzuTbHmXOhG4tacip6lICVQ5djs4c29mR+4Y7vz2xk0iv6cj341sNPe3NV3C54HeXueNDU8YUcu6Tz3D/tIlA25vXklUbWPF1I69u891cMskq6oettvagcjm3Gxc+tZP7zu3LDUEK3h5YXM6IXhks+raK43u6ePzVxfz2mtaKLxSR+NGDnXPvu1v4+37h76urWq2XmbUzovt2lET5/zUgrSSUZGmBnSEZbJl7o9s/b9uBcTkwjiaiL5mKnvZYOJ2RyeVbDf3D4j18tc9J77x+gLvGYVBuI99s2o7t2GFtbl5vPjSdYZc/HLLRnHcjeusbO5V1TSz42s6E4dZWBW8NTQ7stfW8dnE3bny7nrtPzeb2dz/h5xd+P6JNMpKAbbBzZv6wHxQfn7CNMREDgTQgrSSceG9yVfv3smbWtJbfm+yVbHtsKsbRROOAg9k+xYcMbRULqS63tSrIE+NqecpPFKG6ocbrXr7V0JOGG15eVcu4/9uOxWLBGEN5RROF32yPyea1ZNUGduw5QE2tncfOyebGtyvpXpDP4AF9W3zp3oD2sQOzmXCYg1X7XJxZErn1EEnANhmH7yRCpnScUBcT5SAiZwOPAhZgrjHm/lismy4kUyO4tpAMK70nBBYZlc2/O2jWUbLJDweVwqDhowO6ocYL/2row0YcytRTbWwYcD5nTJlG+d5dsGwOd0w+iYkzZnV483rzoektoznPHVPIent1q6d1W5Wdrzds41cTM/lqbxMnFVu46o0DWDIyKNizKiLlEEnANhHDd9pKUU2ETMmoJDtKh5WDiFiA2cBZQCmwQkTeNMZ83dG104VE+fnbQ2HvoqAB70a/rq3JzIq352N2f8nX29fy1JTW3VDjpahDVUPn7/2YM6ZMY/1/3+S3p7i/12CbV7gOq8Foy40x761lXD+uF8cfmsfGnXv47iArFx6RSVZOHp+VWSK+T6QE27Dj1WcoGVtUpOOEulhYDmOBTcaYLQAi8iIwCVDlkADa2vzaE7MI1nrCd81IiPa+7Y2teN07pxySTUZjDcN6Z7XqhtqWom7vfUNVQ3tp2ruRIQO+H/L9YBteuEKwttwY3ifZR5fayMRJjxyhptHQLdvO1LFFMd1YbVV2fnjjI+RRHxCPiPUmnm4tKpKZWCiHYsA3DaEU+G4M1lXaQbjNr71PzcFaT3jXjJRon8rbO6PCUWvjgiF1rNzUxF8n5lNXXcGUMT24dL7beoi1nJFQXb6fQwozyMgI3hsr1IYXrhCsLdeUN7Xy5Kv+wD8mZtMzN4PKAy6ueL2BeV8cYHAM3R1zXl2CHKjge6MKWnonefs/RbOJR2JppFtGUDITC+UQLEHFBJwkch1wHcDlM+7h1IlTYnBrJRpSyb0VKb6fqbmumqoXbiEvP4MJhdUML8pka0UVvQt7cUqPffzPNedQ2+hi17aNLddb/Cq/48GOtcsYf1RJyPfbs+FF4sbwupZOPuJgu47ptuqYZhLZquy8uugTZo3P5e7F9Xx/ZFar/k/RfKa2LI10zAhKZmKhHEoB33/5g4Dd/icZY54AngB4cumWAOWhJAfJ1JcoWqpXL2TSCOHLbfUsrm7m5W9rqGlw4bBspKGhiZyBI2iotrcaQNQZld+71vyXM286Jeh78dzwOiNIOufVJZxZ0sx3B3VjwggXdc5mXnvfPZPi1Uvcbb8j+UyRuIvSMSMomYmFclgBjBCRocAu4BLg0hismzYkS21CJLSnL1GyUL91FS/VNADdcBxopEfvIqxZ0KPvYHaUVTHkigepmhXfrCV/nA4HRTmQaQ3e5iSeG168g6Req+G5iVlkZghTj8li8it1FGZlcvxAa1SfKRLrKR0zgpKZDisHY4xDRKYD7+BOZf2HMWZdhyVLI5Ix3TMdGXzFgy0/b5l7IzN8Um+9wXT/NuLeJnvxUtQ7N33N2KHdQ76fyhvevLeWcdYhTkSsfL2/GYBj+sEzX9azdp+FhVsPfiaH00Xlx4vD9mZqy3pKx4ygZCYmdQ7GmIXAwlispXSMcFZKsGB0pGuufmBKwNQ5MS7umz6lU5RfqGB6tGNSR/tZQPHuGrv907f49cWjQr4fyw2vPa21O4JbseWwuJUT2cq4owM7u3q7x4brzaTuouRCK6TTjHAb9X3Tp7TLvXXnrBc8rqXWwex1c2ewc9vmDqW4RkqoYPqq+36S1C67xsrd9Cg4ulPu1Z7W2u2lrXbj/ueGiyeksvWUzqhy6ELEesN2NtTT/5J7AormOpr9FMxKCDXSs0ef/hE9+Sci7mPbU8rh/Tsni6Y9rbWjDXr7Wh3RKJm24gnqLkpOVDkoSUcwK8F/pOe6uTNwNtTTbK9g+nkntri8fCfP+VowiYj7lK5fzUWj+7d9YgxoT2vtaK0Hr0KY/fJiliz/MiIlo+mnqYtOrFdSjnVzZ3BgfylOY5CcAkx2Hhl5PbH2LMZaUMSwax9j2LWPtTvGEiv2r/svpx83PO738W7AU8e4N9upY/JY8OEKyqvrojonknvMuaCIF95ZxjnDxKNkDs61Dka4eIKS3KjloMSVaKqyvedW2spadYa15HRrdZ6zoZ5+F9/TMpYUQKxZ7PnnzVikM5qGR0bvzCakE+SJtrW2ze7g+pf38P3B+cx+eTFfbiptM0Dtvb53NwvZppHxhx5UMuEsAY0npC6qHJSICOazb7ZXtDmmNJp2HpW2MjLze2Ep6MPAKx/C0dSIAfbMu5WMzBx2P38nezMsGJcL42rG1dzYcq1pbsI4HTQ12Dv2QWPElq9WcMLQXp1yr2hba1fUHqCHtYnV+1x0z/ucXplNYV1Mvq6heSurueyoTKzOBhxOV8jMIm984qm7r1b3UYqiyqEL0p4eSyFHeb7zF7YEWScS/BXHjk3fkNmrmD3zbuVA2Q6MpwuLq8HO4Gtns/vpmzl6+hw+v/9iQMjIzAbAGBciGYjFCiY5iu9LV33AjecdGnA8Hp1KI22tbauyc9X/PE1edhVPTMzjujfqcBnDnB+Hjx34Wh1LNtWxu6aZJz9vAmsp3fNygEBLIBk7pyrRocqhCxKrHkvxCPKKNQvJsGDt0Q9jDCAYp4PdT98c4F5KZhzlOxnY58iA44ncNOe9tYzNW7bzk6NyGdm3F6cVV7J2n5ORfXuHDVC3tkxyIDuH7tkwsG9gPQNo59R0QZWDknyIkJmVTXNTY4uyOHr6HL+TDM22nZ6f3NaC016BcTS3ar8dK6KxtmoqbQzpkxNwbiI3TVuVndfe/4zeuYbxQ500NDkYP9TJh5sbKa9zho0d+CsAX+snGNo5NT1Q5aB0Knt3bsHpdFJpc/vHvR1S24pd+CLGxf5X/kBmfmuffm6fEnJpalX3EKvhPtFYW9/+9y1uPjWwKjqRm+a8t5bRJ7OBU4ZkMqSnhdKySob0tDBpZCb/XFHFraf3jrgqOZz1o6mr6YMqByUksdhY/QPZ3qBzTtEgnA31LR1S3d1R3daA017J7qdvxuFo9sQRnK3W9NYxRLJZJ6JNefOe9Rw+6aRWxxK5aXrvnd3s4PmvHDy7pondtQ4skgECLpp4fp37O24ri6gt60dbYaQPqhyUkMRiY/VXIr5tONbNndHSBK/ZXgFAZn4vcvsMYvS1D7VYGXtfvKvVPb3uos6oeA6XXuvbp8k7t/rCX95DZnNNwGCfRG6a3nvfeuohLcceXtq+uQ5tWT+dnboar1GkiiqHLkmytBD33Vy3zL3RpzlgUyv5SoYcmrDOtl4FuWvbRrKLBrdKr921bWPL+FRLUy1Dux3gP39/gF+eGTg8KJH5/rG6dyTWT2e3wtCsqPihyqELkqwtxJNVLl8Mnowqi5XsosFk5veiZMo97J9zKQ9dNpIL/7GUI6++qSVtVBCevvuqqDfNWD4Rx2rDTjaXkWZFxRdVDkrC2btzS8sTuC+hYhvtiYV4ezF5abZXMPOqCRHHTywWC422HTgdDiTD2hIXseR0c0+gG2VlSO8chnZ38eaHqwHYvGU7PXKkXZtnLJ6Ix06bja22MeB4UUF22PnUoUi2amfNioovqhyUTiXcGFL/aXOhYhvRxEK892uwldH/kntajntnR0caP/F2g/W6l7IKenH09Dktc6sv+H4We6qbmHh4Lq+9/xkul6F3rmHmKZncv3h5VE+1sXoittU2MvpngRP81j05I+q1ILm6p2pWVPxR5aCEJB6xic4eQ+q938yrJgS0Fg/GfdOnsGv71pYury6Xk6pHriUjM4f+E28NON87t7pnbgYL15Vz/ug8Pt1uo6GpmbNGZXLcACunDWzdnqItl5E+EbdNsrm40hFVDkGIVW58qtPZn9WbneTF62rqzO/dbq+l78V/bEmxbbCVYlwu9s2/i51PzwCLBRELiLBm1jSstbt4LsPB859Cs6ln/uosqmrqGZgPU4/JpTBXGD+0mdt9rIdkrhOIR/ZPuDXbe79kc3GlI6ocgpCI3HgFnE5ny6YM7rTWYdc+ltDvPadoEABZBb1otldQfNl9rRQYwN4X72JgySFcdHwJwwqcfLT0Q04pdlGU505nHdLT0mI9TD13XFLXCcQj+yfcmu29XyQuLk1z7Rg6z0FRoqB/yTCKh4xo9epZ1JfzL/spPzpmEEtWbeDTHQ089EkDxQ9VUfxQFcf/rZanV9WxZNUGP5dR4FyDJas28PzaRk6YXdbyen5tI0tWbYj7Z/ONdQSb9WCrsnPhHX+NeAZEW2u2db+O4qt4lOhRy0FJON7Yhrd62kuoRnvtiYXEu7Zj+6oPmHDLqZx30siQ59iq7Ey+7dFOqxMoKsgOGnwuKsgOen5bsY72POWHWzOesRVNc+04qhyUhOMbNA7mzgt1fnvuES8G5pk2B/t0tssomnTVtmId7dlsw61pjIlrbEWD+h1HlYOi+JCfX8Cu+Xe3ZCt5EeMiIyP4n0tz4wGO6J/b5trJHERtS3G1Z7Nta0To6SVw/ct7eGLywJgqykQH9dMFVQ5BSJb2El2NZPjew1kY902fElQ+i6uJiSce1ubayVQn4E84xeUNoke72YZbE+CrzTX0sDbxncdK6VWQ2/JeR5VDooP66YKYBEzOenLpluQY16V0WbyN8qbc9mfyC3t2aK13//JLXv519JtOqmTTPPzcu7Drc249tfDgsXY27vPijb/MmdCNaQvqefnBm2P2HUycMYvdZbaA46GGE3Vpxt0Y0heqloPSJVnx9nys+9by0av/oHTz10GVhH+9S3W5DZdxIcbV0jbc5XCQ2VQFuDfJaFpWxCNtNB4KJx7usHjGBFQBxIYOKQcReRA4D2gCNgNXG2OqYiCX0kXpjALE2qoK1i99ndnnF3PpMy/SP8/wp2k/xpnV2n1VaSuj+LL7Alpn7H765pbAeeXX/6X2g7+2XBNpy4p4ZdPEQ+HEerPVmEBq0FHLYRFwpzHGISIPAHcCt3dcLKWr0pECxEgVy4q353PeCOiZZ6UAO/9zZl+ueWk/A696lMxuB10na2ZNCyh48+fAjjVkZWW1KZs/sXhy9rcSUiV9U2MCqUGHiuCMMe8aYxyeXz8FBnVcJEVpH17F4v/yVRheq2HKmEJeXlHGpUdlMTCrnkkjLVSvWhj1PU1jfcBgn7bwbuJTx7g37qlj8tpVBOZf5NVWgV2ykMhCPyVyYlkhfQ3wdgzXU5SY47UaAN77upwrj82hMAfOH2XBfLuI5vrqiNeq37WBwoGHtH2iH22leEaCf3Xxhh1lUSucUBXP7amEjoY3H5rOymd+H/DSWEFy0aZyEJH3ROSrIK9JPufMBBzAc2HWuU5EVorIyqVvdp3mdUpysXH1x8xf08APHtvEcf2gvM5BZb2LntkwaYREZT1Ur/+E/iOPDzjeVFfDmufupak+0MUFsXly9rcSbp/1cpsKx3/TD9VeQttOKBBBzMEY84Nw74vIlcAE4EwTJi/WGPME8ARoKqsSO3xTUiPh+j89C8Dfbruc/+zdwX88uqCqfD/W/AZc3VfB96YA7vYde1+8i8aivkDrbKXNT07nQMUeLFs+atWOoqggmzV/u5X+mbWs+est5BYUthz30tEn5GAB3b/N2sbW0lyeX9s6U8o3o8h30w/VADBV4hZK/OlottLZuAPQpxlj6ts6X1HaItpCOG9K6vKFL0Z1H6+S8HLf9CnUVFfSvGsjm/42jQyLlVygT4j51fbqSuzv/pnfThnX6vjC+6705O+XePL3r4/55hrMLXX9uF5h6w78N/26xqagAXFtO6F46VARnIhsArKBcs+hT40xN7R1nVoOSiyorarg2TsvYfaEPH6xoI5y050DDQ0B50WaBvvBC3PY/v5TbK3PDUhr9V9n5VvPcMPh9Rx3WOscDN+CsYeXVmPvdRRfbiqNad1Be4q8fOX646JKXltXz3vX9qMo34rN7mDyS7X89a6fccM9T/LS5IJWx2NZoKYkGfEqgjPGDO/I9YrSEbzB5eF9czlvRB0bBpzJGVOmtWst39qHi59cH5DWCq3TaWu2fsno8ae0ej+Yu+eUvy2jfzdansBjMdc5WreUv1ziaubMkmZ65LpDjt74RLi4hVoPXQ+tkFZSEu9m/ruL3Rv4lDGFXDr/dcaOv6Rd7TB8Fc2kUVbeXrWQIk/swZ97p02mYtcmRq1c3eq4rWwvVx8t7ClrYk8ZVB5wkdFczy3f6cYjH7r997Ge6xwJ/m6oFTsb+LbMwb8fKqV7Xs5B+Wt2snNPTlI2BlQ6H1UOSkri3cx752UC7v+eNwKWL3wxauvBX9FccHgWCxcvonnM+ADrAaCqfB8jzr2OgUee2Or4h3+8hNe39+T17e7fGw/UcfFhWQzuTkLrDgLbX+TQvTBHew0pYVHloKQkG1d/zOqyBuavKW11PH/vx1ErB39F0zM3g0kjhDdDWA+OxgP0O+y4gOONmQUcM30O4E5n3fr8b7ns1O5Y6ve0tIhwOqOvpg5HJG4qVQBKe1DloKQk/tlGHcFf0VSV12LNt7ZKa/VijEFcDixZwaepedm3ahGTRgi98qw01B/03z/4sT1mckPkvZwUJVpUOShdnmBprXZ7LTQ2tApC5+cXsG/nVrKsljbXrNy6lvk1jcz/ai/N9lqKi9xJIY7GA7EVXlHihCoHRfEjXNrrijf/QU5OeKsB4Oipv2/5ed2TM1j5zK2A2w0UzVxnRUkUqhwUJQoqNq+huKh70A0+K8O0ufFHM9dZURKJKgdFiZDGhgP0K7Dwim7wShdAlYOiRMimtSv54ZH9Ei1GK4oKstVNpcQFVQ6KEiH7Vi/iRz8dk2gxWqFuKiVexHKeg6KkNTlNFeRkZ0Z0brxnIihKvFHloCghqK2q4MmZP8VeXcmuzd9wVEmviK/VmQhKqqPKQVFC4NsOfNvK95j03WERXec/pU2tByUVUeWgKEHw9lt66Pxi1i99nZpdGzl0UJ+Irk2VWc6KEg5VDooSBN8urWcPdbF/5+aIrvNaDdHMclaUZESVg6L44bUapoxxd2Tt281QX7kvog0+2JQ2tR6UVERTWRXFD/8urdv2H+CCw7MiGnoT2B7bjc5EUFINVQ6K4odvl1ZjDBUVNRxSlMvAirY3eG2PraQLqhwUxQ/fLq17tq2n2xfP8quLTgxzhaKkHxpzUJQwbPx4IZedfniixVCUTkeVg6KEIadhPwOKAkeFKkq6o8pBUUJQW1VB94yGRIuhKAlBlYOihGDjJ//hgnGHJVoMRUkIqhwUJQS2jasYO3JgosVQlISgykFRgtDYcICeWU4yI5gXrSjpiCoHRQnCjvVfcvoRfRMthqIkDFUOihKEXave5yenjk60GIqSMGKiHETkVyJiRKQoFuspSqJxVe9Vl5LSpemwchCREuAsYEfHxVGUxLNn+2aOKemeaDEUJaHEwnL4C3AbYGKwlqIknF1ff8apozVLSenadEg5iMhEYJcx5ssIzr1ORFaKyMqlb77QkdsqSlwp37CScUcOSbQYipJQ2my8JyLvAf2DvDUT+A0QUR9iY8wTwBMAr68uVStDSVrGHjEE8jRTSenaiDHt26dF5CjgfaDec2gQsBsYa4zZGxvxQt77Oo+ySWpSRU5QWeOFyhofVNb4027lELCQyDbgBGOMLSYLhr/XSmPMCfG+T0dJFTlBZY0XKmt8UFnjj9Y5KIqiKAHEbNiPMWZIrNZSFEVREkuqWg6p4r9LFTlBZY0XKmt8UFnjTMxiDoqiKEr6kKqWg6IoihJHUlo5pEJPJxH5HxFZIyJfiMi7IpK0pbci8qCIfOuR93UR6ZFomUIhIj8RkXUi4hKRpMwEEZGzRWS9iGwSkTsSLU8oROQfIlImIl8lWpZwiEiJiCwWkW88/+9/mWiZQiEiOSKyXES+9Mj6h0TLFC0pqxxSqKfTg8aYo40xxwILgLsTLE84FgFHGmOOBjYAdyZYnnB8BVwALE20IMEQEQswGzgHOAKYIiJHJFaqkDwNnJ1oISLAAcwwxhwOnAj8Iom/00bgDGPMMcCxwNkicmJiRYqOlFUOpEhPJ2NMjc+veSSxvMaYd40xDs+vn+IubExKjDHfGGPWJ1qOMIwFNhljthhjmoAXgUkJlikoxpilQEWi5WgLY8weY8wqz8+1wDdAcWKlCo5xY/f8mul5Je3ffjBSUjlE09MpGRCRe0VkJ3AZyW05+HIN8HaihUhhioGdPr+XkqQbWSoiIkOA44DPEixKSETEIiJfAGXAImNM0soajJjVOcSaWPV06gzCyWqMecMYMxOYKSJ3AtOB33WqgD60JavnnJm4TfjnOlM2fyKRNYmRIMdS6skxWRGRfOBV4GY/yzypMMY4gWM9sbvXReRIY0xSx3V8SVrlYIz5QbDjnp5OQ4EvRQTcro9VIhL3nk6hCCVrEJ4H3iKByqEtWUXkSmACcKZJcJ5zFN9rMlIKlPj87u09pnQAEcnErRieM8a8lmh5IsEYUyUiS3DHdVJGOaScW8kYs9YY09cYM8RTlV0KjEmUYmgLERnh8+tE4NtEydIWInI2cDsw0RhT39b5SlhWACNEZKiIZAGXAG8mWKaURtxPg38HvjHGPJxoecIhIn282X4ikgv8gCT+2w9GyimHFOR+EflKRNbgdoUlbfodMAsoABZ5Um//mmiBQiEi54tIKXAS8JaIvJNomXzxBPanA+/gDpy+ZIxZl1ipgiMiLwCfACNFpFREfppomUJwMnAFcIbn3+cXIjI+0UKFYACw2PN3vwJ3zGFBgmWKCq2QVhRFUQJQy0FRFEUJQJWDoiiKEoAqB0VRFCUAVQ6KoihKAKocFEVRlABUOSiKoigBqHJQFEVRAlDloCiKogTw/0bthewVFtrPAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1008x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot   as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from   mlxtend.plotting     import plot_decision_regions\n",
    "from   sklearn.linear_model import LogisticRegression\n",
    "from   sklearn.datasets     import make_classification, make_circles, make_moons\n",
    "%matplotlib inline  \n",
    "\n",
    "X, y = make_classification(n_samples=200, \n",
    "               n_features=2, \n",
    "               n_informative=2,\n",
    "               n_redundant=0, \n",
    "               n_classes=2, \n",
    "               random_state=42)\n",
    "\n",
    "# X, y = make_moons(n_samples=200, \n",
    "#                   random_state=42)\n",
    "\n",
    "# X, y = make_circles(n_samples=200, \n",
    "#                   random_state=42)\n",
    "\n",
    "\n",
    "clf1 = LogisticRegression()\n",
    "gs = gridspec.GridSpec(3, 2)\n",
    " \n",
    "fig = plt.figure(figsize=(14,10))\n",
    " \n",
    "labels = ['Logistic Regression']\n",
    "\n",
    "for clf, lab, grd in zip([clf1], labels,[(0,0)]):\n",
    "    clf.fit(X, y)\n",
    "    ax = plt.subplot(gs[grd[0], grd[1]])\n",
    "    fig = plot_decision_regions(X=X, y=y, clf=clf, legend=2)\n",
    "    plt.title(lab)\n",
    " \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e14c5e",
   "metadata": {},
   "source": [
    "<center><h2>When to use logistic regression</h2></center>\n",
    "\n",
    "Overall - logistic regression is a relatively simple algorithm that empirically performs well on a wide range of problems.\n",
    "\n",
    "It is good choice for an \"advanced\" baseline model.\n",
    "\n",
    "It is relatively straightforward to interpret the coefficients and the entire model.\n",
    "\n",
    "It is fast to both train and predict.\n",
    "\n",
    "It predicts the probability of class membership which is useful (some other classification algorithms do not inherently generate probabilities.\n",
    "\n",
    "It is a common algorithm so there is common ground for communicate and almost all established libraries support an implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b86b9b",
   "metadata": {},
   "source": [
    "<center><h2>When to not use logistic regression</h2></center>\n",
    "\n",
    "Since it is simple, it often will not yield the best performance in an evaluation metric.\n",
    "\n",
    "It requires a lot of feature engineering. Features should be standardized - rescaled to be between 0 and 1. Feature standardized is useful for optimization and for regularization. The coefficients need to be explicitly defined, either by hand or programmatically.\n",
    "\n",
    "Since it learns a hyperplane, assumes there is a linear separation between target classes.\n",
    "\n",
    "Completely fails when there are non-linear separable targets:\n",
    "<br>\n",
    "<center><img src=\"images/circles.png\" width=\"75%\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6214e7",
   "metadata": {},
   "source": [
    "<center><h2>Check for understanding</h2></center>\n",
    "\n",
    "Logistic regression mainly used for regression problems.\n",
    "\n",
    "A) True ¬†üëç    \n",
    "B) False üòÆ\n",
    "\n",
    "Solution: B\n",
    "\n",
    "Logistic regression is a classification algorithm. It is poorly named. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c9dff8",
   "metadata": {},
   "source": [
    "<center><h2>Check for understanding</h2></center>\n",
    "\n",
    "Which of the following methods do we use to best fit the data in Logistic Regression?\n",
    "\n",
    "A) Least Square Error  üëè   \n",
    "B) Maximum Likelihood  üòÇ  \n",
    "C) Cosine distance     ‚ù§Ô∏è  \n",
    "\n",
    "Solution is: B Maximum Likelihood. \n",
    "\n",
    "We have defined a the likelihood as the probability of making a correct prediction and want to be as high as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef5d317",
   "metadata": {},
   "source": [
    "<center><h2>What to learn next</h2></center>\n",
    "\n",
    "- Gradient descent to optimize a loss function.\n",
    "- Regularization by adding a penalty term to loss function.\n",
    "- Evaluation metrics for classification.\n",
    "- Multi-class classification.\n",
    "- Build deep neural networks by stacked logistic regressions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208292c3",
   "metadata": {},
   "source": [
    "<center><h2>Takeaways</h2></center>\n",
    "\n",
    "- Logistic regression is the classification version of linear regression.\n",
    "- It uses the sigmoid function to make predict for probability of the positive class (aka, encoded as $1$).\n",
    "- Logistic regression learns a hyperplane (a straight decision boundary in feature space).\n",
    "- Logistic regression is a simple (but useful) model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d0e27f",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br> \n",
    "<br>\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc43a210",
   "metadata": {},
   "source": [
    "<center><h2>Sources of Inspiration</h2></center>\n",
    "\n",
    "- https://medium.com/@sitingkoh1808/metis-project-5-prediction-of-breast-cancer-d2bb3e89e31f\n",
    "- https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic)\n",
    "- https://github.com/parrt/msds621\n",
    "- https://openclassrooms.com/en/courses/6389626-train-a-supervised-machine-learning-model/6405876-understand-the-logistic-regression-algorithm\n",
    "- [Speech and Language Processing (3rd edition) by Jurafsky and Martin](https://web.stanford.edu/~jurafsky/slp3/)\n",
    "- https://en.wikipedia.org/wiki/Logistic_regression\n",
    "- https://www.analyticsvidhya.com/blog/2017/08/skilltest-logistic-regression/\n",
    "- https://predictivehacks.com/decision-boundary-in-python/\n",
    "- https://www.youtube.com/watch?v=F_VG4LNjZZw&ab_channel=ArtificialIntelligence-AllinOne"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d500ee",
   "metadata": {},
   "source": [
    "<center><h2>Bonus Material</h2></center>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42af70ea",
   "metadata": {},
   "source": [
    "<center><h2>Can you fit logistic regression with categorical variables?</h2></center>\n",
    "\n",
    "Yes - typically you one-hot encode them.\n",
    "\n",
    "The parameter (or weight) of each categorical is how much the presence of that feature impact the probability of class 1.\n",
    "\n",
    "The can be visualized with a bar plot with each bar representing the estimated probability of observing a specific outcome in that condition. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d98a3a3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _breast_cancer_dataset:\n",
      "\n",
      "Breast cancer wisconsin (diagnostic) dataset\n",
      "--------------------------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 569\n",
      "\n",
      "    :Number of Attributes: 30 numeric, predictive attributes and the class\n",
      "\n",
      "    :Attribute Information:\n",
      "        - radius (mean of distances from center to points on the perimeter)\n",
      "        - texture (standard deviation of gray-scale values)\n",
      "        - perimeter\n",
      "        - area\n",
      "        - smoothness (local variation in radius lengths)\n",
      "        - compactness (perimeter^2 / area - 1.0)\n",
      "        - concavity (severity of concave portions of the contour)\n",
      "        - concave points (number of concave portions of the contour)\n",
      "        - symmetry\n",
      "        - fractal dimension (\"coastline approximation\" - 1)\n",
      "\n",
      "        The mean, standard error, and \"worst\" or largest (mean of the three\n",
      "        worst/largest values) of these features were computed for each image,\n",
      "        resulting in 30 features.  For instance, field 0 is Mean Radius, field\n",
      "        10 is Radius SE, field 20 is Worst Radius.\n",
      "\n",
      "        - class:\n",
      "                - WDBC-Malignant\n",
      "                - WDBC-Benign\n",
      "\n",
      "    :Summary Statistics:\n",
      "\n",
      "    ===================================== ====== ======\n",
      "                                           Min    Max\n",
      "    ===================================== ====== ======\n",
      "    radius (mean):                        6.981  28.11\n",
      "    texture (mean):                       9.71   39.28\n",
      "    perimeter (mean):                     43.79  188.5\n",
      "    area (mean):                          143.5  2501.0\n",
      "    smoothness (mean):                    0.053  0.163\n",
      "    compactness (mean):                   0.019  0.345\n",
      "    concavity (mean):                     0.0    0.427\n",
      "    concave points (mean):                0.0    0.201\n",
      "    symmetry (mean):                      0.106  0.304\n",
      "    fractal dimension (mean):             0.05   0.097\n",
      "    radius (standard error):              0.112  2.873\n",
      "    texture (standard error):             0.36   4.885\n",
      "    perimeter (standard error):           0.757  21.98\n",
      "    area (standard error):                6.802  542.2\n",
      "    smoothness (standard error):          0.002  0.031\n",
      "    compactness (standard error):         0.002  0.135\n",
      "    concavity (standard error):           0.0    0.396\n",
      "    concave points (standard error):      0.0    0.053\n",
      "    symmetry (standard error):            0.008  0.079\n",
      "    fractal dimension (standard error):   0.001  0.03\n",
      "    radius (worst):                       7.93   36.04\n",
      "    texture (worst):                      12.02  49.54\n",
      "    perimeter (worst):                    50.41  251.2\n",
      "    area (worst):                         185.2  4254.0\n",
      "    smoothness (worst):                   0.071  0.223\n",
      "    compactness (worst):                  0.027  1.058\n",
      "    concavity (worst):                    0.0    1.252\n",
      "    concave points (worst):               0.0    0.291\n",
      "    symmetry (worst):                     0.156  0.664\n",
      "    fractal dimension (worst):            0.055  0.208\n",
      "    ===================================== ====== ======\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Class Distribution: 212 - Malignant, 357 - Benign\n",
      "\n",
      "    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\n",
      "\n",
      "    :Donor: Nick Street\n",
      "\n",
      "    :Date: November, 1995\n",
      "\n",
      "This is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\n",
      "https://goo.gl/U2Uwz2\n",
      "\n",
      "Features are computed from a digitized image of a fine needle\n",
      "aspirate (FNA) of a breast mass.  They describe\n",
      "characteristics of the cell nuclei present in the image.\n",
      "\n",
      "Separating plane described above was obtained using\n",
      "Multisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\n",
      "Construction Via Linear Programming.\" Proceedings of the 4th\n",
      "Midwest Artificial Intelligence and Cognitive Science Society,\n",
      "pp. 97-101, 1992], a classification method which uses linear\n",
      "programming to construct a decision tree.  Relevant features\n",
      "were selected using an exhaustive search in the space of 1-4\n",
      "features and 1-3 separating planes.\n",
      "\n",
      "The actual linear program used to obtain the separating plane\n",
      "in the 3-dimensional space is that described in:\n",
      "[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\n",
      "Programming Discrimination of Two Linearly Inseparable Sets\",\n",
      "Optimization Methods and Software 1, 1992, 23-34].\n",
      "\n",
      "This database is also available through the UW CS ftp server:\n",
      "\n",
      "ftp ftp.cs.wisc.edu\n",
      "cd math-prog/cpo-dataset/machine-learn/WDBC/\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \n",
      "     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \n",
      "     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\n",
      "     San Jose, CA, 1993.\n",
      "   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \n",
      "     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \n",
      "     July-August 1995.\n",
      "   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\n",
      "     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \n",
      "     163-171.\n"
     ]
    }
   ],
   "source": [
    "# The empirical dataset from the motivating story\n",
    "# Try to fit with a logistic regression!\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "data = load_breast_cancer()\n",
    "print(data.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2fdcd7",
   "metadata": {},
   "source": [
    "<center><h2>Extending logistic regression to build deep neural networks</h2></center>\n",
    "\n",
    "<br>\n",
    "<center><img src=\"images/function_3.png\" width=\"75%\"/></center>\n",
    "\n",
    "<br>\n",
    "<center><img src=\"images/stacked.png\" width=\"75%\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1567211a",
   "metadata": {},
   "source": [
    "<center><h2>Logistic Function</h2></center>\n",
    "\n",
    "Logistic Function is differentiable which is handy for learning.\n",
    "\n",
    "The sigmoid function has the property:\n",
    "\n",
    "$$1‚àíœÉ(x) = œÉ(‚àíx)$$\n",
    "\n",
    "thus  we could also have expressed P(y = 0) as œÉ (‚àíùë•Œ≤)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f554905f",
   "metadata": {},
   "source": [
    "<center><h2>Odds</h2></center>\n",
    "Given:\n",
    "$$ p(x) = œÉ(xŒ≤) = \\frac{1}{1+‚ÑØ^{-xŒ≤}} $$\n",
    "and:\n",
    "$$ odds = \\frac{p}{1-p} $$\n",
    "\n",
    "Substitute in ùëù(ùê±).\n",
    "\n",
    "Simplify.\n",
    "\n",
    "Take log.\n",
    "\n",
    "$$ log(odd) = xŒ≤ $$\n",
    "\n",
    "The unit of measurement for the log-odds scale is called a logit, from __log__istic un<b>it<b>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d57b59",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br> \n",
    "<br>\n",
    "\n",
    "----"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
